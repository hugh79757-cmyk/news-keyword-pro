import os
import requests

def crawl_news(category_id, query):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ APIë¡œ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ê°€ì ¸ì˜¤ê¸°"""
    print(f"    ğŸ” ê²€ìƒ‰ì–´: {query}")
    
    client_id = os.getenv("NAVER_CLIENT_ID")
    client_secret = os.getenv("NAVER_CLIENT_SECRET")
    
    if not client_id or not client_secret:
        print("    âŒ ë„¤ì´ë²„ API í‚¤ ì—†ìŒ")
        return []
    
    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret
    }
    params = {
        "query": query,
        "display": 50,
        "sort": "date"
    }
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        
        data = response.json()
        items = data.get("items", [])
        
        headlines = []
        for item in items:
            # HTML íƒœê·¸ ì œê±°
            title = item.get("title", "")
            title = title.replace("<b>", "").replace("</b>", "")
            title = title.replace("&quot;", '"').replace("&amp;", "&")
            title = title.replace("&lt;", "<").replace("&gt;", ">")
            
            if title and len(title) > 10:
                headlines.append(title)
        
        # ì¤‘ë³µ ì œê±°
        headlines = list(dict.fromkeys(headlines))
        return headlines[:35]
        
    except Exception as e:
        print(f"    âŒ API ì—ëŸ¬: {e}")
        return []
