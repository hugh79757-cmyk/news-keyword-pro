import os
from datetime import datetime, timezone, timedelta
from dotenv import load_dotenv

load_dotenv()

from config import NEWS_CATEGORIES, KEYWORDS_PER_CATEGORY
from src import news_crawler, analyzer, naver_api, builder

def main():
    print("=" * 60)
    print("ğŸš€ ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„ ë´‡ (Pro Edition)")
    print("=" * 60)
    
    kst = timezone(timedelta(hours=9))
    now = datetime.now(kst)
    print(f"â° ì‹¤í–‰ ì‹œê°„: {now.strftime('%Y-%m-%d %H:%M')} KST")
    print(f"ğŸ“‚ ì¹´í…Œê³ ë¦¬: {len(NEWS_CATEGORIES)}ê°œ\n")
    
    all_results = {}
    
    for category_id, category_info in NEWS_CATEGORIES.items():
        print(f"\n{'â”€'*60}")
        print(f"{category_info['icon']} [{category_info['name']}] ì²˜ë¦¬ ì‹œì‘")
        print("â”€" * 60)
        
        # 1. ë‰´ìŠ¤ API í˜¸ì¶œ
        print(f"\n  [1/4] ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
        headlines = news_crawler.crawl_news(category_id, category_info['query'])
        
        if not headlines:
            print(f"    âš ï¸ ë‰´ìŠ¤ ì—†ìŒ, ìŠ¤í‚µ")
            all_results[category_id] = []
            continue
        
        print(f"    âœ… {len(headlines)}ê°œ í—¤ë“œë¼ì¸ ìˆ˜ì§‘")
        
        # 2. AI í‚¤ì›Œë“œ ì¶”ì¶œ
        print(f"\n  [2/4] AI í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
        keywords = analyzer.extract_keywords(headlines, category_info['name'])
        
        if not keywords:
            print(f"    âš ï¸ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨, ìŠ¤í‚µ")
            all_results[category_id] = []
            continue
        
        # 3. ë„¤ì´ë²„ API ë¶„ì„
        print(f"\n  [3/4] í‚¤ì›Œë“œ ë¶„ì„ ì¤‘...")
        keyword_results = naver_api.analyze_keywords(keywords, KEYWORDS_PER_CATEGORY)
        
        # ì—°ê´€ê²€ìƒ‰ì–´ ì¡°íšŒ (ìƒìœ„ 5ê°œë§Œ)
        related_data = []
        for item in keyword_results[:15]:
            related = naver_api.get_autocomplete(item['keyword'])
            related_data.append({
                "keyword": item['keyword'],
                "related": related[:5]
            })
        
        all_results[category_id] = keyword_results
        
        # 4. ì¹´í…Œê³ ë¦¬ í˜ì´ì§€ ìƒì„±
        print(f"\n  [4/4] í˜ì´ì§€ ìƒì„± ì¤‘...")
        builder.build_category_page(category_id, category_info, keyword_results, related_data)
        
        # 5. CSVì— ì €ì¥
        builder.save_to_csv(category_info['name'], keyword_results)
    
    # ë©”ì¸ í˜ì´ì§€ ìƒì„±
    print(f"\n{'='*60}")
    print("ğŸ“„ ë©”ì¸ í˜ì´ì§€ ë° ì•„ì¹´ì´ë¸Œ ìƒì„±")
    print("=" * 60)
    
    builder.build_index_page(all_results)
    builder.build_archive_page()
    
    # ì™„ë£Œ ìš”ì•½
    print(f"\n{'='*60}")
    print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print("=" * 60)
    
    total_keywords = sum(len(results) for results in all_results.values())
    print(f"ğŸ“Š ì´ {total_keywords}ê°œ í‚¤ì›Œë“œ ë¶„ì„ë¨")
    
    for cat_id, results in all_results.items():
        cat_info = NEWS_CATEGORIES[cat_id]
        print(f"   {cat_info['icon']} {cat_info['name']}: {len(results)}ê°œ")
    
    print(f"\nğŸ“ CSV ì €ì¥: output/history.csv")


if __name__ == "__main__":
    main()
